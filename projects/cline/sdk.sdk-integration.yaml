# SDK Integration Analysis: Cline
# Spec: specs/sdk-integration.spec.yaml

project: "cline"
sdk_integration_detected: true

summary: |
  Direct Anthropic SDK integration via @anthropic-ai/sdk v0.37.0 with full streaming support,
  prompt caching (ephemeral cache control on last 2 user messages), extended thinking with
  budget tokens, native tool calling, and 1M context window support via beta headers.

sdks_used:
  - name: "anthropic-typescript"
    package: "@anthropic-ai/sdk"
    version_constraint: "^0.37.0"
    import_reference:
      path: "src/core/api/providers/anthropic.ts"
      lines: [1, 3]
      snippet: |
        import { Anthropic } from "@anthropic-ai/sdk"
        import { Tool as AnthropicTool } from "@anthropic-ai/sdk/resources/index"
        import { Stream as AnthropicStream } from "@anthropic-ai/sdk/streaming"

  - name: "anthropic-vertex"
    package: "@anthropic-ai/vertex-sdk"
    version_constraint: "^0.6.4"
    import_reference:
      path: "package.json"
      lines: [1, 5]
      snippet: |
        "@anthropic-ai/vertex-sdk": "^0.6.4"

sdk_usage:

  - id: streaming-messages-create
    sdk: "anthropic-typescript"
    pattern: "messages-create-stream"
    description: "Primary streaming message creation with prompt caching and extended thinking"

    reference:
      repository: "https://github.com/cline/cline"
      commit: "844038084c6e559ee131c32e5d5da93dcff68a73"
      path: "src/core/api/providers/anthropic.ts"
      lines: [66, 116]
      function: "createMessage"
      class: "AnthropicHandler"
      language: "typescript"

    api_methods:
      - "client.messages.create"

    parameters:
      - name: "model"
        value_type: "string"
        purpose: "Model selection"
        example_value: "claude-sonnet-4-5-20250929"
      - name: "thinking"
        value_type: "object"
        purpose: "Extended thinking with budget tokens"
        example_value: "{ type: 'enabled', budget_tokens: 6000 }"
      - name: "max_tokens"
        value_type: "integer"
        purpose: "Response length limit"
        example_value: "8192"
      - name: "temperature"
        value_type: "float"
        purpose: "Sampling temperature (disabled when thinking enabled)"
        example_value: "0"
      - name: "stream"
        value_type: "boolean"
        purpose: "Enable streaming"
        example_value: "true"
      - name: "tools"
        value_type: "array"
        purpose: "Native tool calling definitions"
      - name: "tool_choice"
        value_type: "object"
        purpose: "Tool selection strategy"
        example_value: "{ type: 'any' }"

    snippet: |
      stream = await client.messages.create({
        model: modelId,
        thinking: reasoningOn ? { type: "enabled", budget_tokens } : undefined,
        max_tokens: model.info.maxTokens || 8192,
        temperature: reasoningOn ? undefined : 0,
        system: [{
          text: systemPrompt, type: "text",
          cache_control: { type: "ephemeral" },
        }],
        messages: anthropicMessages,
        stream: true,
        tools: nativeToolsOn ? tools : undefined,
        tool_choice: nativeToolsOn && !reasoningOn ? { type: "any" } : undefined,
      }, enable1mContextWindow ? {
        headers: { "anthropic-beta": "context-1m-2025-08-07" },
      } : undefined);

    notes: |
      Uses prompt caching (ephemeral) on system message and last 2 user messages.
      Extended thinking enabled when model supports it and budget > 0 (min 1024, max 6000).
      1M context window via beta header. Native tool calling with streaming.

    checklist_refs:
      - "sdk-features.checklist.yaml#messages-stream"
      - "sdk-features.checklist.yaml#tool-use"

  - id: stream-event-processing
    sdk: "anthropic-typescript"
    pattern: "stream-events"
    description: "Processes streaming events including thinking, text, and tool_use blocks"

    reference:
      repository: "https://github.com/cline/cline"
      commit: "844038084c6e559ee131c32e5d5da93dcff68a73"
      path: "src/core/api/providers/anthropic.ts"
      lines: [120, 240]
      function: "createMessage"
      class: "AnthropicHandler"
      language: "typescript"

    snippet: |
      for await (const chunk of stream) {
        switch (chunk?.type) {
          case "message_start":
            // Usage tracking: cache reads/writes
            yield { type: "usage", inputTokens, outputTokens, cacheWriteTokens, cacheReadTokens };
            break;
          case "content_block_start":
            switch (chunk.content_block.type) {
              case "thinking":
                yield { type: "reasoning", reasoning: chunk.content_block.thinking };
                break;
              case "redacted_thinking":
                yield { type: "reasoning", reasoning: "[Redacted]", redacted_data };
                break;
              case "tool_use":
                // Convert to internal tool format
                break;
              case "text":
                yield { type: "text", text: chunk.content_block.text };
                break;
            }
        }
      }

    notes: "Handles thinking, redacted_thinking, text, and tool_use content blocks"

agents_sdk_features: {}

patterns_summary:
  messages-stream: true
  tool-use: true
  prompt-caching: true
  extended-thinking: true
  agent-create: false
  1m-context-window: true
