# Project Metadata: AlphaCodium
# Spec: specs/project.spec.yaml

name: "alphacodium"
display_name: "AlphaCodium"
repository: "https://github.com/Codium-ai/AlphaCodium"
description: "Code generation framework using LiteLLM abstraction layer; supports Claude models via configuration but has no direct Anthropic SDK or Claude CLI integration"
analyzed_commit: "eb7577dbe998ae7e55696264591ac3c5dde75638"
analyzed_at: "2026-02-07"

website: ""
documentation: ""
license: "AGPL-3.0"
primary_language: "Python"
languages: [Python]
tags: [code-generation, litellm, multi-provider, benchmark]

integration_types: [sdk]

analysis_status: "comprehensive"

notes: |
  Minimal Claude integration: uses LiteLLM acompletion() as abstraction layer.
  No direct Anthropic SDK import, no Claude CLI invocation.
  Claude models supported via LiteLLM routing (model name prefix determines provider).
  Default model is GPT-4; Claude usable by setting model="claude-3-opus" in config.
  Features: async completion, model fallback chains, rate limiting, configurable timeout.
  README mentions Claude 3 Opus benchmarking on AlphaCodium leaderboard.
  Token encoding defaults to cl100k_base for non-GPT models.

related_projects: ["aider", "openhands"]
